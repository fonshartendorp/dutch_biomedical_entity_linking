{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ce249b",
   "metadata": {},
   "source": [
    "# Dutch HPO concept table\n",
    "This notebook describes how to create a HPO concept table containing Dutch names, to be used in a named entity recognition and linking tool such as MedCAT. Dutch names are added to HPO concepts in 4 steps:\n",
    "\n",
    "1. Names from Dutch HPO translations\n",
    "2. Names from Dutch UMLS (MeSH, MedDRA, ICPC and ICD-10) and SNOMED\n",
    "3. Manual UMCU additions\n",
    "4. Removal of UMCU blacklisted names\n",
    "\n",
    "## Preprocessing translation file\n",
    "In 2021, we received the Dutch HPO translations `hpo_notes.xliff_nl.zip` from Sebastian KÃ¶hler (lead of the HPO translation project on CrowdIn at the time) with permission from David Koolen (Radboud UMC). David's team did the translations, which mostly consists of primary names, and a few synonyms and definitions (14% of all HPO names, see https://crowdin.com/project/hpo-translation/nl). With David's permission , Sebastian shared the translations with UMC Utrecht.\n",
    "\n",
    "The translation file, `hpo_notes.xliff_nl.zip`, was manually unzipped and converted to XLSX-format with Excel (Right click file -> Open With -> All apps -> Select Excel -> Wait a file minutes). The resulting file was saved as `hpo_notes.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc7df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from utils import clean_name_status_column, convert_title_to_lowercase\n",
    "\n",
    "# Input & output\n",
    "source_hpo_files_path = Path('01_Download/hpo/')\n",
    "concept_table_path = Path('04_ConceptDB')\n",
    "output_file = concept_table_path / 'hpo-dutch_v1.2.csv'\n",
    "\n",
    "# Dutch HPO translations, required for first part of this notebook\n",
    "hpo_translations_file = source_hpo_files_path / 'hpo_notes.xlsx'\n",
    "\n",
    "# Dutch names from UMLS and SNOMED, required for second part of this notebook\n",
    "umls_concept_table_path = Path('04_ConceptDB/umls-dutch_v1.11.csv')\n",
    "\n",
    "# Manualy additions and deletions, required for last part of this notebook\n",
    "hpo_umcu_names_file = source_hpo_files_path / 'hpo-dutch_umcu-names_20221116.csv'\n",
    "blacklisted_names_file = source_hpo_files_path / 'hpo-dutch_umcu-blacklist_20221601.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c6f30b",
   "metadata": {},
   "source": [
    "## 1. Names from Dutch HPO translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9146e571",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '01_Download/hpo/hpo_notes.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read HPO translations file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m hpo_translations \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhpo_translations_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Rename columns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m hpo_translations \u001b[38;5;241m=\u001b[39m hpo_translations\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/file/body/trans-unit/@id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/file/body/trans-unit/note\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/file/body/trans-unit/source\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/file/body/trans-unit/target\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/file/body/trans-unit/target/@state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/stack/research_project/datasets/dutch-medical-concepts/venv/lib/python3.8/site-packages/pandas/io/excel/_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n",
      "File \u001b[0;32m~/stack/research_project/datasets/dutch-medical-concepts/venv/lib/python3.8/site-packages/pandas/io/excel/_base.py:1496\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1503\u001b[0m         )\n",
      "File \u001b[0;32m~/stack/research_project/datasets/dutch-medical-concepts/venv/lib/python3.8/site-packages/pandas/io/excel/_base.py:1371\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1369\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1374\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1375\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/stack/research_project/datasets/dutch-medical-concepts/venv/lib/python3.8/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '01_Download/hpo/hpo_notes.xlsx'"
     ]
    }
   ],
   "source": [
    "# Read HPO translations file\n",
    "hpo_translations = pd.read_excel(hpo_translations_file, dtype=str, header=1) \n",
    "\n",
    "# Rename columns\n",
    "hpo_translations = hpo_translations.rename(columns={\"/file/body/trans-unit/@id\": \"id\",\n",
    "                            \"/file/body/trans-unit/note\": \"full_name\",\n",
    "                            \"/file/body/trans-unit/source\": \"english_name\",\n",
    "                            \"/file/body/trans-unit/target\": \"name\",\n",
    "                            \"/file/body/trans-unit/target/@state\": \"state\"})\n",
    "\n",
    "# Select columns to keep\n",
    "hpo_translations = hpo_translations[['id', 'full_name', 'english_name', 'name', 'state']]\n",
    "\n",
    "# Replace substrings at the end of the cui-values\n",
    "substrings = ['_label', '_definition', '_synonyms'] # Substrings to replace\n",
    "hpo_translations['cui'] = hpo_translations.id.str.replace('|'.join(substrings), '', regex=True).str.strip()\n",
    "hpo_translations.head()\n",
    "\n",
    "# Filter the terms that are translated\n",
    "total_terms = hpo_translations['cui'].nunique() # Get total number of HPO-terms\n",
    "hpo_translations = hpo_translations[hpo_translations['state'] == \"translated\"]\n",
    "hpo_translations = hpo_translations.drop(columns=['full_name', 'english_name', 'state'])\n",
    "hpo_translations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract type\n",
    "def extract_type(r):\n",
    "    return r['id'].split('_')[2]\n",
    "hpo_translations['type'] = hpo_translations.apply(extract_type, axis=1)\n",
    "\n",
    "# Count number of '#' in hpo_translations. This is number of synonyms that have to be corrected.\n",
    "counter=0\n",
    "for i, r in hpo_translations.iterrows():\n",
    "    if '#' in r['name']:\n",
    "        counter += 1\n",
    "print('Number of synonyms that have to be corrected because it includes #:', counter)\n",
    "\n",
    "# Clean names. The synonyms contains # at start and as separators.\n",
    "def clean_synonyms(r):\n",
    "    concept_id = r['id']\n",
    "    concept_name = r['name']\n",
    "\n",
    "    # Return all non synonyms, because they are already clean\n",
    "    if not 'synonyms' in concept_id:\n",
    "        return [concept_name]\n",
    "\n",
    "    # Return all synonyms that are already clean\n",
    "    if not '#' in concept_name:\n",
    "        return [concept_name]\n",
    "\n",
    "    # Clean and split synonym\n",
    "    cleaned_names = [n.strip() for n in concept_name.strip('#').split('#')]\n",
    "    \n",
    "    # Remove duplicates\n",
    "    cleaned_names = list(set(cleaned_names))\n",
    "    return cleaned_names\n",
    "\n",
    "hpo_translations['cleaned_names'] = hpo_translations.apply(clean_synonyms, axis=1)\n",
    "hpo_translations_cleaned_names = hpo_translations.explode('cleaned_names')\n",
    "\n",
    "# Replace name column\n",
    "hpo_translations_cleaned_names = hpo_translations_cleaned_names.drop(columns=['name'])\n",
    "hpo_translations_cleaned_names.rename(columns={'cleaned_names':'name'}, inplace=True)\n",
    "print('Number of synonyms that are added because multiple synonyms were in same field:', len(hpo_translations_cleaned_names)-len(hpo_translations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'definition'. These are longer descriptions of the concept and less usefull for named entity recognition\n",
    "hpo_translations_definitions_removed = hpo_translations_cleaned_names[hpo_translations_cleaned_names['type'].isin(['label', 'synonyms'])].copy()\n",
    "print('Number of names that are removed because they are definition: ', len(hpo_translations_cleaned_names) - len(hpo_translations_definitions_removed) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert title-formatted names to lowercase\n",
    "hpo_translations_definitions_removed['name'] = hpo_translations_definitions_removed['name'].apply(convert_title_to_lowercase, split_char=' ')\n",
    "hpo_translations_definitions_removed['name'] = hpo_translations_definitions_removed['name'].apply(convert_title_to_lowercase, split_char='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc033e",
   "metadata": {},
   "source": [
    "### Finalize structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e76ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_translations_fs = hpo_translations_definitions_removed.copy()\n",
    "\n",
    "# Impute ontology\n",
    "hpo_translations_fs['ontologies'] = \"HPO_dutch_translation\"\n",
    "\n",
    "# Set name status, see https://github.com/CogStack/MedCAT/blob/master/examples/README.md\n",
    "hpo_translations_fs['name_status'] = \"unknown\"\n",
    "hpo_translations_fs['name_status'][hpo_translations_fs['type'] == 'label'] = 'P'\n",
    "hpo_translations_fs['name_status'][hpo_translations_fs['type'] == 'synonyms'] = 'A'\n",
    "\n",
    "# Replace the underscores with colons in the concept ID\n",
    "hpo_translations_fs['cui'] = hpo_translations_fs['cui'].str.replace('_', ':', regex=True)\n",
    "hpo_translations_fs = hpo_translations_fs.drop(columns=['id', 'type'])\n",
    "\n",
    "# Print statistics\n",
    "print('Number of concepts:', len(hpo_translations_fs['cui'].unique()))\n",
    "print('Number of names:', len(hpo_translations_fs))\n",
    "\n",
    "hpo_translations_fs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f2d55",
   "metadata": {},
   "source": [
    "### Manual corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_translations_mc = hpo_translations_fs.copy()\n",
    "\n",
    "# Correct Respiratory Failure\n",
    "# Respiratory Insufficiency / C0035229 / 409623005 / HP:0002093 / https://uts.nlm.nih.gov/uts/umls/concept/C0035229\n",
    "# Respiratory Failure / C1145670 / 409622000 / HP:0002878 / https://uts.nlm.nih.gov/uts/umls/concept/C1145670\n",
    "print(f\"Current HP:0002093\\n{hpo_translations_mc.loc[hpo_translations_mc.cui == 'HP:0002093', 'name']}\\n\")\n",
    "print(f\"Current HP:0002878\\n{hpo_translations_mc.loc[hpo_translations_mc.cui == 'HP:0002878', 'name']}\\n\")\n",
    "hpo_translations_mc.loc[hpo_translations_mc.cui == 'HP:0002878', 'name'] = 'respiratoir falen'\n",
    "print(f\"Corrected HP:0002878\\n{hpo_translations_mc.loc[hpo_translations_mc.cui == 'HP:0002878', 'name']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e5862",
   "metadata": {},
   "source": [
    "## 2. Names from Dutch UMLS and SNOMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1bddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read UMLS concept table\n",
    "umls_concepts = pd.read_csv(umls_concept_table_path, dtype=str, usecols=['cui', 'name', 'ontologies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials to connect to UMLS MySQL hpo_translationsbase\n",
    "load_dotenv()\n",
    "user = os.getenv('MYSQL_USER')\n",
    "password = os.getenv('MYSQL_PASSWORD')\n",
    "host = os.getenv('MYSQL_HOST')\n",
    "port = os.getenv('MYSQL_PORT')\n",
    "hpo_translationsbase = os.getenv('MYSQL_DATABASE')\n",
    "\n",
    "# Create the connection\n",
    "connection_string = f'mysql://{user}:{password}@{host}:{port}/{hpo_translationsbase}'\n",
    "connection = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eafa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to retrieve UMLS to HPO mapping\n",
    "query = \"SELECT DISTINCT CUI, CODE FROM MRCONSO WHERE SAB = 'HPO'\"\n",
    "umls_hpo_mapping = pd.read_sql_query(query, con=connection)\n",
    "print(f'HPO concepts with UMLS CUI: {len(umls_hpo_mapping)}')\n",
    "umls_hpo_mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5274ab6",
   "metadata": {},
   "source": [
    "### UMLS concepts maps that map to multiple HPO concepts\n",
    "There are a few UMLS concepts that map to multiple HPO concepts. This pipeline does not add names from these UMLS concepts to HPO, because it will cause ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List a few examples\n",
    "print(f'UMLS concepts that map to multiple HPO concepts: {len(umls_hpo_mapping[umls_hpo_mapping.CUI.duplicated()])}')\n",
    "umls_hpo_mapping[umls_hpo_mapping.CUI.duplicated(keep=False)].sort_values(['CUI']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0996f4",
   "metadata": {},
   "source": [
    "### Multiple UMLS concepts map to single HPO concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Multiple UMLS concepts that map to a single HPO concept: {len(umls_hpo_mapping[umls_hpo_mapping.CODE.duplicated()])}')\n",
    "umls_hpo_mapping[umls_hpo_mapping.CODE.duplicated(keep=False)].sort_values(['CODE']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61807ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records of UMLS concepts that map to multiple HPO concepts.\n",
    "# Keep records of multiple UMLS concepts that map to a single HPO concept in.\n",
    "umls_hpo_mapping = umls_hpo_mapping[~umls_hpo_mapping.CUI.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd90fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use primary names from translations\n",
    "umls_concepts['name_status'] = 'A'\n",
    "\n",
    "# Merge UMLS names with HPO-UMLS mapping\n",
    "umls_hpo_concepts = umls_hpo_mapping.merge(umls_concepts, left_on='CUI', right_on='cui', how='inner')\n",
    "umls_hpo_concepts.drop(['CUI', 'cui'], axis=1, inplace=True)\n",
    "umls_hpo_concepts.rename(columns={'CODE': 'cui'}, inplace=True)\n",
    "umls_hpo_concepts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20485469",
   "metadata": {},
   "source": [
    "### Merge translations and UMLS/SNOMED names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b816e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names from translations\n",
    "number_cui_translations = len(hpo_translations_fs.cui.unique())\n",
    "number_names_translations = len(hpo_translations_fs)\n",
    "print(f'Number of concepts from translations: {number_cui_translations}')\n",
    "print(f'Number of names from translations: {number_names_translations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names from UMLS and SNOMED\n",
    "number_cui_umls = len(umls_hpo_concepts.cui.unique())\n",
    "number_names_umls = len(umls_hpo_concepts)\n",
    "print(f'Number of concepts from UMLS and SNOMED: {number_cui_umls}')\n",
    "print(f'Number of names from UMLS: {number_names_umls}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69126460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tables\n",
    "hpo_merged = pd.concat([hpo_translations_fs, umls_hpo_concepts])\n",
    "hpo_merged = hpo_merged.groupby(['cui', 'name'], as_index=False).agg({'ontologies' : '|'.join, 'name_status' : '|'.join}).copy()\n",
    "\n",
    "# Clean name_status column\n",
    "hpo_merged.name_status = hpo_merged.name_status.apply(clean_name_status_column)\n",
    "hpo_merged.sort_values(by=['cui', 'name_status'], ascending=[True, False], inplace=True)\n",
    "hpo_merged.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Print statistics\n",
    "number_cui_merged = len(hpo_merged.cui.unique())\n",
    "number_names_merged = len(hpo_merged)\n",
    "print(f'Number of concepts: {number_cui_merged} (+{number_cui_merged - number_cui_translations})')\n",
    "print(f'Number of names: {number_names_merged} (+{number_names_merged - number_names_translations})')\n",
    "hpo_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ffa735",
   "metadata": {},
   "source": [
    "## 3. Manual UMCU additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_umcu_names = pd.read_csv(hpo_umcu_names_file, dtype='str')\n",
    "\n",
    "# Clean table\n",
    "hpo_umcu_names['name'] = hpo_umcu_names['name'].apply(convert_title_to_lowercase, split_char=' ')\n",
    "hpo_umcu_names['name'] = hpo_umcu_names['name'].apply(convert_title_to_lowercase, split_char='-')\n",
    "hpo_umcu_names['ontologies'] = 'UMCU'\n",
    "hpo_umcu_names['name_status'] = 'A'\n",
    "print('Number of concepts: ', len(hpo_umcu_names.cui.unique()))\n",
    "print('Number of names: ', len(hpo_umcu_names))\n",
    "hpo_umcu_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra names\n",
    "hpo_merged = pd.concat([hpo_merged, hpo_umcu_names])\n",
    "hpo_merged = hpo_merged.groupby(['cui', 'name', 'name_status']).agg({'ontologies': lambda x: \"|\".join(x)}).sort_values(['cui', 'name_status', 'name'], ascending=[True, False, True]).reset_index()\n",
    "\n",
    "number_cui_merged_2 = len(hpo_merged.cui.unique())\n",
    "number_names_merged_2 = len(hpo_merged)\n",
    "print(f'Number of concepts: {number_cui_merged_2} (+{number_cui_merged_2 - number_cui_merged})')\n",
    "print(f'Number of names: {number_names_merged_2} (+{number_names_merged_2 - number_names_merged})')\n",
    "hpo_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9ee06",
   "metadata": {},
   "source": [
    "## 4. Removal of UMCU blacklisted names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ea394",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklisted_names = pd.read_csv(blacklisted_names_file, dtype='str')\n",
    "blacklisted_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_merged = hpo_merged[~hpo_merged['name'].str.lower().isin([x.lower() for x in blacklisted_names.name.tolist()])]\n",
    "number_cui_merged_3 = len(hpo_merged.cui.unique())\n",
    "number_names_merged_3 = len(hpo_merged)\n",
    "print(f'Number of concepts: {number_cui_merged_3} (-{abs(number_cui_merged_3 - number_cui_merged_2)})')\n",
    "print(f'Number of names: {number_names_merged_3} (-{abs(number_names_merged_3 - number_names_merged_2)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a70fe",
   "metadata": {},
   "source": [
    "## Write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99355155",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_merged.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
